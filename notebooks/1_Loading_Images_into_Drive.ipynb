{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwhcZmGEHRb8cR+/lONs+N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "download images from unsplashImages.tsv from the data folder in drive locally (this colab), zip them up, and then send them to drive so that the other colab can download the zip and use the pictures."
      ],
      "metadata": {
        "id": "Kzs3zBES6xWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import requests\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrxHsgdrx4OO",
        "outputId": "1e23ec84-3d72-45df-d14c-4952a66b6bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ3ucVjhxfdE",
        "outputId": "53585aee-1bc2-4728-8e48-a7ff526f27cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['photo_id', 'photo_url', 'photo_image_url', 'photo_submitted_at',\n",
            "       'photo_featured', 'photo_width', 'photo_height', 'photo_aspect_ratio',\n",
            "       'photo_description', 'photographer_username', 'photographer_first_name',\n",
            "       'photographer_last_name', 'exif_camera_make', 'exif_camera_model',\n",
            "       'exif_iso', 'exif_aperture_value', 'exif_focal_length',\n",
            "       'exif_exposure_time', 'photo_location_name', 'photo_location_latitude',\n",
            "       'photo_location_longitude', 'photo_location_country',\n",
            "       'photo_location_city', 'stats_views', 'stats_downloads',\n",
            "       'ai_description', 'ai_primary_landmark_name',\n",
            "       'ai_primary_landmark_latitude', 'ai_primary_landmark_longitude',\n",
            "       'ai_primary_landmark_confidence', 'blur_hash'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# save 2000 image sample sample to drive\n",
        "\n",
        "unsplash_path = '/content/drive/MyDrive/Amortized Optimal Transport/Data/unsplashImages.tsv'\n",
        "unsplash_tsv = glob.glob(unsplash_path)[0]\n",
        "unsplash_df = pd.read_csv(unsplash_tsv, sep='\\t', header=0)\n",
        "print(unsplash_df.columns)\n",
        "unsplash_df = unsplash_df[['photo_id', 'photo_image_url', 'photo_width', 'photo_height']]\n",
        "unsplash_df_sample = unsplash_df.sample(n=2000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image(args):\n",
        "    \"\"\"\n",
        "    args: tuple of (url, save_path)\n",
        "    downloads single image from url to save_path\n",
        "    \"\"\"\n",
        "    url, save_path = args\n",
        "\n",
        "    # append width parameter to url to save bandwidth/storage\n",
        "    if \"?\" in url:\n",
        "        dl_url = f\"{url}&w=512\"\n",
        "    else:\n",
        "        dl_url = f\"{url}?w=512\"\n",
        "\n",
        "    try:\n",
        "        # time out in case a link is bad\n",
        "        response = requests.get(dl_url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            return True\n",
        "        else:\n",
        "          print(f\"Got status code {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        return False\n",
        "    return False\n",
        "\n",
        "def hydrate_dataset(df, output_dir):\n",
        "    \"\"\"\n",
        "    Downloads images from input df to output_dir\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    urls = df['photo_image_url']\n",
        "\n",
        "    # Prepare arguments for threading\n",
        "    tasks = []\n",
        "    for i, url in enumerate(urls):\n",
        "        filename = f\"{i:05d}.jpg\"\n",
        "        save_path = os.path.join(output_dir, filename)\n",
        "        tasks.append((url, save_path))\n",
        "\n",
        "    print(\"Starting threaded download...\")\n",
        "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "        results = list(tqdm(executor.map(download_image, tasks), total=len(tasks)))\n",
        "\n",
        "    print(f\"Successfully downloaded {sum(results)} images to {output_dir}\")\n",
        "\n",
        "def backup_to_drive(local_folder, drive_folder, zip_name='images'):\n",
        "    \"\"\"\n",
        "    Zips local folder and uploads it to Google Drive.\n",
        "    \"\"\"\n",
        "    print(f\"Zipping {local_folder}...\")\n",
        "    archive_path = shutil.make_archive(base_name=f'/content/{zip_name}', format='zip', root_dir=local_folder)\n",
        "\n",
        "    if not os.path.exists(drive_folder):\n",
        "        os.makedirs(drive_folder)\n",
        "\n",
        "    print(f\"Copying to {drive_folder}...\")\n",
        "    try:\n",
        "        shutil.copy(archive_path, drive_folder)\n",
        "        print(\"complete\")\n",
        "    except Exception as e:\n",
        "        print(f\"error: {e}\")"
      ],
      "metadata": {
        "id": "Vm-8Jc29yZYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/dataset/raw_images\"\n",
        "hydrate_dataset(unsplash_df_sample, output_dir)\n",
        "backup_to_drive(output_dir, '/content/drive/MyDrive/Amortized Optimal Transport/Data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpS-QkVt3QIN",
        "outputId": "8d8d4fb4-9b48-46ad-f83f-5ea24b86b417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting threaded download...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [01:13<00:00, 27.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded 2000 images to /content/dataset/raw_images\n",
            "Zipping /content/dataset/raw_images...\n",
            "Copying to /content/drive/MyDrive/Amortized Optimal Transport/Data...\n",
            "complete\n"
          ]
        }
      ]
    }
  ]
}