{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzRuAQq1UGYfMn9OOnXrBP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "MKirtXqFavLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data In\n",
        "Idea: fetching from drive every time is too slow. Instead, store all data in a zip in drive, fetch the whole zip and save all data in colab runtime. Now fetches go to colab SSD which is fast."
      ],
      "metadata": {
        "id": "qOFdVPlnN-90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/Amortized Optimal Transport/Data/images.zip'\n",
        "local_path = '/content/dataset'\n",
        "\n",
        "if not os.path.exists(local_path):\n",
        "  print(\"Getting data zip from google drive...\")\n",
        "  shutil.copy(drive_path, '/content/data.zip')\n",
        "  print(\"Unzipping data locally...\")\n",
        "  !unzip -q /content/data.zip -d {local_path}\n",
        "  print(\"Dataset successfully loaded in /content/dataset\")\n",
        "else:\n",
        "  print(\"Dataset zip already loaded and unzipped locally\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXJoXBlpOKZS",
        "outputId": "995ef27d-fa3a-4670-e100-5299efd9bbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Getting data zip from google drive...\n",
            "Unzipping data locally...\n",
            "Dataset successfully loaded in /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting color palette from input image"
      ],
      "metadata": {
        "id": "Wyqy35NfJT0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia\n",
        "\n",
        "import cv2\n",
        "import kornia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJfZPzsxMFA-",
        "outputId": "87b278ff-1855-43ea-8166-ddbe36db2f51",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kornia\n",
            "  Downloading kornia-0.8.2-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia)\n",
            "  Downloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from kornia) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->kornia) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->kornia) (3.0.3)\n",
            "Downloading kornia-0.8.2-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kornia_rs, kornia\n",
            "Successfully installed kornia-0.8.2 kornia_rs-0.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title fast_kmeans(x, k, max_iters=100, tol=1e-3)\n",
        "def fast_kmeans(x, k, max_iters=100, tol=1e-3):\n",
        "    \"\"\"\n",
        "    GPU kmeans implementation.\n",
        "    kmeans_pytorch has an issue where if a center has no members you get 0/0 = NaN center_shift\n",
        "    Consequently had to make my own kmeans\n",
        "\n",
        "    Args:\n",
        "        x (Tensor): data of shape (N, D)\n",
        "        k (int): number of clusters\n",
        "    Returns:\n",
        "        labels (Tensor): (N,) cluster assignments\n",
        "        centers (Tensor): (k, D) cluster centers\n",
        "    \"\"\"\n",
        "    # pick k random points to start in\n",
        "    N, D = x.shape\n",
        "    indices = torch.randperm(N, device=x.device)[:k]\n",
        "    centers = x[indices].clone()\n",
        "\n",
        "    labels = torch.zeros(N, dtype=torch.long, device=x.device)\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        centers_old = centers.clone()\n",
        "\n",
        "        #calculate distances\n",
        "        dists = torch.cdist(x, centers)\n",
        "        labels = torch.argmin(dists, dim=1)\n",
        "\n",
        "        new_centers = torch.zeros(k, D, device=x.device)\n",
        "        counts = torch.zeros(k, device=x.device)\n",
        "\n",
        "        #sum coordinates of points in each cluster\n",
        "        new_centers.index_add_(0, labels, x)\n",
        "\n",
        "        # count points in each cluster\n",
        "        ones = torch.ones(N, device=x.device)\n",
        "        counts.index_add_(0, labels, ones)\n",
        "\n",
        "        # Replace 0s with 1s to avoid 0/0 division\n",
        "        # empty clusters will be discarded later\n",
        "        counts_safe = torch.clamp(counts, min=1).unsqueeze(1)\n",
        "        candidates = new_centers / counts_safe\n",
        "\n",
        "        # If count > 0, use candidate. If count == 0, keep centers_old.\n",
        "        valid_mask = (counts > 0).unsqueeze(1)\n",
        "        centers = torch.where(valid_mask, candidates, centers_old)\n",
        "\n",
        "        shift = torch.norm(centers - centers_old)\n",
        "        if shift < tol:\n",
        "            break\n",
        "\n",
        "    return labels, centers"
      ],
      "metadata": {
        "id": "1wZlgTqEG0JP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get_palette(image_path, k=128, testing=False)\n",
        "def get_palette(image_path, k=128, testing=False):\n",
        "  '''\n",
        "  Runs k-means clustering on the Lab-space colors of the input picture.\n",
        "  RGB distance is not useful, Delta E distance in Lab space correctly models how differenently humans view colors.\n",
        "\n",
        "  Want everything to run on GPU so we use kornia for rgb to lab conversion. kmeans_pytorch for kmeans\n",
        "\n",
        "  Parameters:\n",
        "    image_path: string path to image in local colab env. Should be /content/dataset/XXXXX.jpg\n",
        "    k: number of clusters to make in k-means\n",
        "    testing: if True, will imshow the image get_palette is called on\n",
        "\n",
        "  Returns:\n",
        "    Centroids: (k, 3) Lab coordinates of all k cluster means\n",
        "    Weights: (k,) probability distribution weighing each cluster proportional to the number of elements in it\n",
        "    Pixel labels: (h*w,) cluster membership per pixel\n",
        "  '''\n",
        "  device = 'cuda'\n",
        "\n",
        "  image = cv2.imread(image_path) # a numpy array\n",
        "\n",
        "  # Important note: bgr2rgb was used here rather than bgr2lab as opencv's\n",
        "  #                 lab doesn't give me the right scaling that I need between\n",
        "  #                 the L, a, b values. Has to do because they use 8 bit \"quantization,\"\n",
        "  #                 but I didn't look too deep into what that meant\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  image_tensor = torch.from_numpy(image_rgb).permute(2, 0, 1) # get to (3, height, width)\n",
        "  image_tensor = image_tensor.unsqueeze(0).to(device) # (1, 3, height, width). kornia expects (batch size, num channels, height, width)\n",
        "  image_tensor = image_tensor.float() / 255.0\n",
        "\n",
        "  lab_image_tensor = kornia.color.rgb_to_lab(image_tensor) #bgr_to_lab does not exist\n",
        "\n",
        "  if testing:\n",
        "    print(type(image_rgb))\n",
        "    print(image_rgb.shape)\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(type(lab_image_tensor))\n",
        "    print(lab_image_tensor.shape)\n",
        "    # plot from cpu\n",
        "    lab_vis = lab_image_tensor[0].permute(1,2,0).cpu().detach().numpy()\n",
        "    plt.imshow(lab_vis)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "  pixels = lab_image_tensor[0].view(3, -1).permute(1, 0).contiguous() #-1 here implicitly combines height and width\n",
        "\n",
        "  #kmeans only cares about color distance so we view lab_image_tensor to just be ((h*w), 3)\n",
        "  cluster_ids_x, cluster_centers = fast_kmeans(x=pixels, k=k)\n",
        "\n",
        "  counts = torch.bincount(cluster_ids_x, minlength=k)\n",
        "  weights = counts / counts.sum()\n",
        "\n",
        "  return cluster_centers.cpu(), weights.cpu(), cluster_ids_x.cpu()"
      ],
      "metadata": {
        "id": "_tSKthbgJXzd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through dataset, run get_palette on each image, save all kmeans palette outputs locally\n",
        "\n",
        "def save_palettes_locally(k=128):\n",
        "  palette_dir = '/content/palettes/'\n",
        "  data_dir = '/content/dataset/'\n",
        "  if not os.path.exists(palette_dir):\n",
        "    os.makedirs(palette_dir)\n",
        "\n",
        "  filepaths = sorted(os.listdir(data_dir))\n",
        "\n",
        "  centroid_tensor = torch.empty(len(filepaths), k, 3)\n",
        "  weights_tensor = torch.empty(len(filepaths), k)\n",
        "  memberships_list = []\n",
        "  for i, filepath in tqdm(enumerate(filepaths)):\n",
        "    centroids, weights, memberships = get_palette(data_dir + filepath, k=k, testing=False)\n",
        "    centroid_tensor[i] = centroids\n",
        "    weights_tensor[i] = weights\n",
        "    memberships_list.append(memberships)\n",
        "\n",
        "  torch.save({\n",
        "      'centroids': centroid_tensor,\n",
        "      'weights': weights_tensor,\n",
        "      'memberships': memberships_list,\n",
        "      'filenames': filepaths\n",
        "  }, os.path.join(palette_dir, \"palette_bank.pt\"))\n",
        "\n",
        "def save_palettes_to_drive():\n",
        "  palette_dir = '/content/palettes/'\n",
        "  drive_dir = '/content/drive/MyDrive/Amortized Optimal Transport/Data'\n",
        "\n",
        "  print(\"Zipping Palettes...\")\n",
        "  archive_path = shutil.make_archive(base_name=f'/content/palettes', format='zip', root_dir=palette_dir)\n",
        "  if not os.path.exists(drive_dir):\n",
        "    os.makedirs(drive_dir)\n",
        "\n",
        "  print(\"Copying palettes to drive...\")\n",
        "  try:\n",
        "    shutil.copy(archive_path, drive_dir)\n",
        "    print(\"Done\")\n",
        "  except Exception as e:\n",
        "    print(f\"error: {e}\")\n"
      ],
      "metadata": {
        "id": "zvhqxRnQULlx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_palettes_locally(k=128)\n",
        "save_palettes_to_drive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnx_unZL3jwL",
        "outputId": "645d8914-af20-4c00-9a90-12af7e727d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [14:24,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipping Palettes...\n",
            "Copying palettes to drive...\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}